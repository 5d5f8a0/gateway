{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1YnDHZY6owEypgSgvJJgXPcntxOjy9GpS?usp=sharing)\n"
      ],
      "metadata": {
        "id": "L81TWFYhHM-K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build a Chatbot with Guardrails: Using Langchain and Portkey to Enforce PII Detection and more\n",
        "\n",
        "In this tutorial, we'll create a customer support chatbot using LangChain and Portkey guardrails to protect sensitive information, focusing on preventing PII exposure in logs.\n",
        "\n",
        "\n",
        "Portkey's **Guardrails** offer real-time enforcement of LLM behavior, with features including:\n",
        "\n",
        "- **Regex matching** and **JSON Schema validation**\n",
        "- **Code detection**\n",
        "- **Custom guardrail**s: Integrate your existing guardrail systems custom guardrail integration\n",
        "-** LLM-based guardrails** (e.g., gibberish detection, prompt injection scanning)\n",
        "\n",
        "With **20+ deterministic guardrail**s and integrations with platforms like **Aporia, Pillar and Patronus AI,** Portkey provides comprehensive AI safety solutions. Guardrails can be configured for inputs, outputs, or both, with actions ranging from request denial to alternative LLM fallbacks.\n",
        "\n",
        "For more details, visit the [Portkey Guardrails documentation](https://docs.portkey.ai/docs/product/guardrails/list-of-guardrail-checks/patronus-ai).\n",
        "\n",
        "\n",
        "Let's build our guardrail-protected chatbot!"
      ],
      "metadata": {
        "id": "cWj7GyUW76uP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting Up Portkey Guardrails\n",
        "\n",
        "Before building our chatbot, let's configure Portkey guardrails for PII detection:\n",
        "\n",
        "1. Sign Up for [portkey.ai](https://portkey.ai) (the dev account is free ferver) ðŸŽŠ\n",
        "2. Enable Patronus AI in the [Integrations page](https://app.portkey.ai/integrations) on Portkey App\n",
        "3. Navigate to the [Guardrails dashboard](https://app.portkey.ai/guardrails)\n",
        "4. Create a new guardrail, by selecting \"Detect PII Guardrail\" by Patronus AI\n",
        "6. Save and copy your Config ID\n",
        "\n",
        "\n",
        "\n",
        "This Config ID is crucial for integrating PII protection into our LangChain-Portkey  chatbot. With this setup, we're ready to create a secure, PII-aware conversational AI.\n",
        "\n",
        "\n",
        "![O](https://raw.githubusercontent.com/siddharthsambharia-portkey/Portkey-Product-Images/main/Portkey_PII_Guardrails.png)\n",
        "\n"
      ],
      "metadata": {
        "id": "RhXlcYb5NFqj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Setting up the environment\n",
        "\n",
        "First, let's install the necessary packages:"
      ],
      "metadata": {
        "id": "_x0jcajG76AY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXamAIlNgU7J",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install -qU langchain-openai portkey-ai langchain langchain_community"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Importing required libraries and setting up API keys\n",
        "\n",
        "In this step, we'll import the necessary libraries and set up our API keys. We'll also create Portkey config object to add guardrails to protect against PII exposure. Get your Portkey API key from [here](https://app.portkey.ai/api-keys)."
      ],
      "metadata": {
        "id": "E943mJcZG7SX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZShDZzRr-yo",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from typing import Dict\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.chat_history import BaseChatMessageHistory\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "from portkey_ai import createHeaders, PORTKEY_GATEWAY_URL\n",
        "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
        "\n",
        "\n",
        "portkey_config={\n",
        "\t\"before_request_hooks\": [{\n",
        "\t\t\"id\": \"YOUR_CONFIG_ID\" #Enter the config ID you saved from portkey dashboard\n",
        "\t}],\n",
        "\t\"after_request_hooks\": [{\n",
        "\t\t\"id\": \"YOUR_CONFIG_ID\" #Enter the config ID you saved from portkey dashboard\n",
        "\t}]\n",
        "}\n",
        "\n",
        "\n",
        "model = ChatOpenAI(\n",
        "    api_key=\"YOUR_OPENAI_API_KEY\", #Enter your OpenAI API key\n",
        "    base_url=PORTKEY_GATEWAY_URL,\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    default_headers=createHeaders(\n",
        "        provider=\"openai\",\n",
        "        api_key=\"YOUR_PORTKEY_API_KEY\" #Enter your Portkey API key\n",
        "        config=portkey_config,\n",
        "    )\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code sets up our environment with the necessary configurations for Portkey guardrails. The portkey_config defines our guardrail settings, including retry attempts, caching, and hooks for request and response processing.\n",
        "\n"
      ],
      "metadata": {
        "id": "IeIvEQiIG9y-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Creating the chat prompt template and chain\n",
        "\n",
        "Now, let's set up our chat prompt template and create a chain that combines the prompt with our Portkey-protected model. This structure allows us to maintain a conversation history while applying guardrails to each interaction."
      ],
      "metadata": {
        "id": "TdMZ3Mx378rd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create a chat prompt template\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful assistant. Answer all questions to the best of your ability.\"),\n",
        "    MessagesPlaceholder(variable_name=\"messages\"),\n",
        "])\n",
        "\n",
        "# Create a chain that combines the prompt and the model\n",
        "chain = prompt | model\n",
        "\n",
        "# Create a dictionary to store chat histories for different sessions\n",
        "store: Dict[str, BaseChatMessageHistory] = {}\n",
        "\n",
        "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
        "    if session_id not in store:\n",
        "        store[session_id] = InMemoryChatMessageHistory()\n",
        "    return store[session_id]\n",
        "\n",
        "# Wrap the chain with message history\n",
        "with_message_history = RunnableWithMessageHistory(\n",
        "    chain,\n",
        "    get_session_history,\n",
        "    input_messages_key=\"messages\",\n",
        ")\n",
        "\n",
        "# Function to chat with the bot\n",
        "def chat_with_bot(session_id: str, user_input: str):\n",
        "    config = {\"configurable\": {\"session_id\": session_id}}\n",
        "    response = with_message_history.invoke(\n",
        "        {\"messages\": [{\"content\": user_input, \"type\": \"human\"}]},\n",
        "        config=config\n",
        "    )\n",
        "    return response.content\n"
      ],
      "metadata": {
        "id": "oL9gBUBu7iLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code creates a chat prompt template, sets up a chain combining the prompt and the Portkey-protected model, and establishes a system for managing chat history. The chat_with_bot function handles individual interactions, applying our guardrails to each message.\n"
      ],
      "metadata": {
        "id": "BdxJenOI79hs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Running the chatbot\n",
        "Finally, we'll implement the main loop for our chatbot. This will allow users to interact with the bot while our Portkey guardrails work in the background to protect sensitive information.\n",
        "\n",
        "Try using this prompt to see guardrails in action- \"My name is Siddharth and I am working at Portkey AI\""
      ],
      "metadata": {
        "id": "D02MN0oLHE2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    session_id = \"abc123\"\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() in ['exit', 'quit', 'bye']:\n",
        "            print(\"Bot: Goodbye!\")\n",
        "            break\n",
        "\n",
        "        response = chat_with_bot(session_id, user_input)\n",
        "        print(f\"Bot: {response}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Z2w0DB0b7j6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "\n",
        "Integrating Portkey with our LangChain-based chatbot has significantly enhanced our AI application's capabilities, reliability, and observability. Portkey offers a comprehensive suite of tools designed to streamline AI development and operations:\n",
        "\n",
        "### AI Gateway\n",
        "- Fast, multimodal gateway supporting multiple LLM providers\n",
        "- Universal API for easy integration\n",
        "- Features like caching, fallbacks, and canary testing\n",
        "- Secure vault for API key management\n",
        "\n",
        "### Reliability\n",
        "- Automatic retries and load balancing\n",
        "- Fallback options and custom timeout management\n",
        "- Caching to reduce costs and latency\n",
        "\n",
        "### Observability\n",
        "- OpenTelemetry-compliant suite for comprehensive insights\n",
        "- Detailed logging and request tracing\n",
        "- Analytics dashboard with 21+ key metrics\n",
        "- Customizable filters and metadata tagging\n",
        "\n",
        "By leveraging these features, we've created a more robust, efficient, and transparent AI application. Portkey's tools not only enhance our chatbot's performance and stability but also provide crucial insights for continuous improvement. As we scale our AI systems, these capabilities will be instrumental in maintaining high-quality service, optimizing resource utilization, and driving data-driven decisions in our AI initiatives."
      ],
      "metadata": {
        "id": "A3BOYCMwFoxF"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
